import requests
import re
import csv
from bs4 import BeautifulSoup
import streamlit as st
import pandas as pd
import io

# GitHub ä¸Šå­˜å‚¨äº§å“ç¼–å·å’Œåç§°å¯¹ç…§è¡¨çš„åŸå§‹ URL
GITHUB_CSV_URL = "https://raw.githubusercontent.com/DaryWang/product-lookup-app/refs/heads/main/KPL.csv"

# å›½å®¶ç½‘ç«™æ¨¡æ¿ï¼ŒæŒ‰è¦æ±‚é¡ºåºæ’åˆ—
URL_TEMPLATES = {
    "Sweden": "https://www.komplett.se/product/{}",
    "Norway": "https://www.komplett.no/product/{}",
    "Denmark": "https://www.komplett.dk/product/{}",
}

# æ­£åˆ™è¡¨è¾¾å¼ï¼šåªæå–æ•°å­—å’Œç¬¦å·ï¼ˆä¾‹å¦‚ï¼Œ`,`å’Œ`.-`ï¼‰
def clean_price(price_text):
    cleaned_price = re.sub(r'[^\d,.-]', '', price_text).strip()
    return cleaned_price

#ä»·æ ¼æå–
def extract_prices(url):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"}
    try:
        response = requests.get(url, headers=headers, allow_redirects=True, timeout=30)
    except Exception as e:
        return 'ERROR', f'è¯·æ±‚å¤±è´¥: {e}'

    if response.status_code != 200:
        return 'ERROR', f'è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}'

    soup = BeautifulSoup(response.text, 'html.parser')

    # æå–å¸¸è§„ä»·æ ¼ï¼ˆå½“å‰ä»·æ ¼ï¼‰
    price_element = soup.find('span', {'class': 'product-price-now'})
    if price_element:
        inc_vat_price = price_element  # æ¨¡æ‹Ÿä½ åŸæ¥çš„ç»“æ„
        regular_price = inc_vat_price.get_text(strip=True) if inc_vat_price else 'N/A'
    else:
        regular_price = 'N/A'
    regular_price = clean_price(regular_price)

    # æå–ä¿ƒé”€ä»·æ ¼ï¼ˆåŸä»·ï¼‰
    promo_price_element = soup.find('span', {'class': 'product-price-before '})
    if promo_price_element:
        promo_price = promo_price_element  # æ¨¡æ‹Ÿä½ åŸæ¥çš„ç»“æ„
        if promo_price:
            promo_price_text = promo_price.get_text(strip=True)
            promo_price_value = promo_price_text.replace('FÃ¸rpris: ', '').replace('Tidigare pris', '').strip()
            promo_price = clean_price(promo_price_value)
        else:
            promo_price = 'N/A'
    else:
        promo_price = 'N/A'

    # å¦‚æœæœ‰ä¿ƒé”€ï¼Œäº¤æ¢ä»·æ ¼å˜é‡
    if promo_price != 'N/A':
        regular_price, promo_price = promo_price, regular_price

    return regular_price, promo_price
# ä» GitHub è¯»å–äº§å“ç¼–å·å’Œåç§°å¯¹ç…§è¡¨
def load_product_mapping_from_github():
    response = requests.get(GITHUB_CSV_URL)
    if response.status_code == 200:
        # ä½¿ç”¨ pandas è¯»å– CSV å†…å®¹
        df = pd.read_csv(io.StringIO(response.text))
        if 'Product ID' in df.columns and 'Product Name' in df.columns:
            return df
        else:
            st.error("GitHub CSV file must contain 'Product ID' and 'Product Name' columns.")
            return None
    else:
        st.error("Failed to load the CSV file from GitHub.")
        return None

# å°†æŸ¥è¯¢ç»“æœä¿å­˜ä¸º TXT æ–‡ä»¶ï¼ˆCSV æ ¼å¼ï¼‰
def save_results_to_txt(product_id, results):
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow(["Product ID", "Country", "Product URL", "Regular Price", "Promo Price"])
    for result in results:
        writer.writerow(result)
    return output.getvalue()

# é¡µé¢è®¾ç½®
st.set_page_config(page_title="Elkjop Price Lookup", layout="centered")

st.title("ğŸ’» Komplett Price Lookup")
st.write("You can either input any Product ID or choose from the dropdown list of TP-Link Models.")

# ä» GitHub åŠ è½½å¯¹ç…§è¡¨
product_mapping_df = load_product_mapping_from_github()

# ç”¨æˆ·è¾“å…¥äº§å“ç¼–å·
product_id_input = st.text_input("Enter the product ID (e.g., 1319905)", "")

# ç”¨æˆ·é€‰æ‹©äº§å“åç§°ï¼ˆå¦‚æœå¯¹ç…§è¡¨å·²åŠ è½½ï¼‰
product_name_input = None
if product_mapping_df is not None:
    product_name_input = st.selectbox(
        "Or select a product name from the list:",
        product_mapping_df['Product Name'].dropna().unique()  # å»é™¤ç©ºå€¼
    )

# æ ¹æ®é€‰æ‹©çš„äº§å“åç§°æˆ–äº§å“ç¼–å·æŸ¥è¯¢ä»·æ ¼
if st.button("Get Prices"):
    if product_id_input.strip():
        selected_product_id = product_id_input.strip()
    elif product_name_input:
        selected_product_id = product_mapping_df.loc[
            product_mapping_df['Product Name'] == product_name_input, 'Product ID'
        ].values
        selected_product_id = selected_product_id[0] if selected_product_id else None
    else:
        st.error("Please enter a product ID or select a product name.")
        selected_product_id = None

    if selected_product_id:
        results = []
        for country, url_template in URL_TEMPLATES.items():
            product_url = url_template.format(selected_product_id)
            regular_price, promo_price = extract_prices(product_url)
            results.append([selected_product_id, country, product_url, regular_price, promo_price])
        
        # æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ
        for result in results:
            st.write(f"**{result[1]}** | **Regular Price**: {result[3]} | **Promo Price**: {result[4]}")  # æ˜¾ç¤ºå›½å®¶
            st.write(f"URL: {result[2]}")
        
        # ä¸‹è½½æŸ¥è¯¢ç»“æœ
        txt_data = save_results_to_txt(selected_product_id, results)
        st.download_button("Download Results", txt_data, file_name="KPL_prices.txt")
