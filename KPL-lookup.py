import requests
import re
import csv
from bs4 import BeautifulSoup
import streamlit as st
import pandas as pd
import io
import random

# GitHub ä¸Šå­˜å‚¨äº§å“ç¼–å·å’Œåç§°å¯¹ç…§è¡¨çš„åŸå§‹ URL
GITHUB_CSV_URL = "https://raw.githubusercontent.com/DaryWang/product-lookup-app/refs/heads/main/KPL.csv"

# å›½å®¶ç½‘ç«™æ¨¡æ¿ï¼ŒæŒ‰è¦æ±‚é¡ºåºæ’åˆ—
URL_TEMPLATES = {
    "Sweden": "https://www.komplett.se/product/{}",
    "Norway": "https://www.komplett.no/product/{}",
    "Denmark": "https://www.komplett.dk/product/{}",
}

def get_random_user_agent():
    # å®šä¹‰å¤šä¸ªå¸¸è§çš„ User-Agent
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_4_0) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Safari/605.1.15",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
    ]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ User-Agent
    if not user_agents:
        raise ValueError("User-Agent list is empty!")
    
    return random.choice(user_agents)

def extract_prices(url, retries=3):
    headers = {
        "User-Agent": get_random_user_agent(),
        "Accept-Language": "en-US,en;q=0.9",
        "Referer": "https://www.google.com/"
    }

    for attempt in range(retries):
        try:
            response = requests.get(url, headers=headers, timeout=20)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')

            # æå–å¸¸è§„ä»·æ ¼ï¼ˆå½“å‰ä»·æ ¼ï¼‰
            price_element = soup.find('span', {'class': 'product-price-now'})
            regular_price = price_element.get_text(strip=True) if price_element else 'N/A'

            # æå–ä¿ƒé”€ä»·æ ¼ï¼ˆåŸä»·ï¼‰
            promo_price_element = soup.find('span', {'class': 'product-price-before '})
            promo_price = promo_price_element.get_text(strip=True) if promo_price_element else 'N/A'

            # å¦‚æœæœ‰ä¿ƒé”€ï¼Œäº¤æ¢ä»·æ ¼å˜é‡
            if promo_price != 'N/A':
                regular_price, promo_price = promo_price, regular_price

            return regular_price, promo_price

        except Exception as e:
            if attempt < retries - 1:
                time.sleep(2)  # å»¶æ—¶ 2 ç§’åé‡è¯•
            else:
                return 'ERROR', f"Request failed: {e}"

    return 'ERROR', "Max retries reached."





# ä» GitHub è¯»å–äº§å“ç¼–å·å’Œåç§°å¯¹ç…§è¡¨
def load_product_mapping_from_github():
    response = requests.get(GITHUB_CSV_URL)
    if response.status_code == 200:
        # ä½¿ç”¨ pandas è¯»å– CSV å†…å®¹
        df = pd.read_csv(io.StringIO(response.text))
        if 'Product ID' in df.columns and 'Product Name' in df.columns:
            return df
        else:
            st.error("GitHub CSV file must contain 'Product ID' and 'Product Name' columns.")
            return None
    else:
        st.error("Failed to load the CSV file from GitHub.")
        return None

# å°†æŸ¥è¯¢ç»“æœä¿å­˜ä¸º TXT æ–‡ä»¶ï¼ˆCSV æ ¼å¼ï¼‰
def save_results_to_txt(product_id, results):
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow(["Product ID", "Country", "Product URL", "Regular Price", "Promo Price"])
    for result in results:
        writer.writerow(result)
    return output.getvalue()

# é¡µé¢è®¾ç½®
st.set_page_config(page_title="Elkjop Price Lookup", layout="centered")

st.title("ğŸ’» Komplett Price Lookup")
st.write("You can either input any Product ID or choose from the dropdown list of TP-Link Models.")

# ä» GitHub åŠ è½½å¯¹ç…§è¡¨
product_mapping_df = load_product_mapping_from_github()

# ç”¨æˆ·è¾“å…¥äº§å“ç¼–å·
product_id_input = st.text_input("Enter the product ID (e.g., 1319905)", "")

# ç”¨æˆ·é€‰æ‹©äº§å“åç§°ï¼ˆå¦‚æœå¯¹ç…§è¡¨å·²åŠ è½½ï¼‰
product_name_input = None
if product_mapping_df is not None:
    product_name_input = st.selectbox(
        "Or select a product name from the list:",
        product_mapping_df['Product Name'].dropna().unique()  # å»é™¤ç©ºå€¼
    )

# æ ¹æ®é€‰æ‹©çš„äº§å“åç§°æˆ–äº§å“ç¼–å·æŸ¥è¯¢ä»·æ ¼
if st.button("Get Prices"):
    if product_id_input.strip():
        selected_product_id = product_id_input.strip()
    elif product_name_input:
        selected_product_id = product_mapping_df.loc[
            product_mapping_df['Product Name'] == product_name_input, 'Product ID'
        ].values
        selected_product_id = selected_product_id[0] if selected_product_id else None
    else:
        st.error("Please enter a product ID or select a product name.")
        selected_product_id = None

    if selected_product_id:
        results = []
        for country, url_template in URL_TEMPLATES.items():
            product_url = url_template.format(selected_product_id)
            regular_price, promo_price = extract_prices(product_url)
            results.append([selected_product_id, country, product_url, regular_price, promo_price])
        
        # æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ
        for result in results:
            st.write(f"**{result[1]}** | **Regular Price**: {result[3]} | **Promo Price**: {result[4]}")  # æ˜¾ç¤ºå›½å®¶
            st.write(f"URL: {result[2]}")
        
        # ä¸‹è½½æŸ¥è¯¢ç»“æœ
        txt_data = save_results_to_txt(selected_product_id, results)
        st.download_button("Download Results", txt_data, file_name="KPL_prices.txt")
