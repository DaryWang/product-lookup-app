import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import io

# --- æŠ“å–å‡½æ•° ---
def extract_product_info(product_id, product_name=""):
    url = f"https://www.kjell.com/se/{product_id}"
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept-Language": "en-US,en;q=0.9"
    }
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
    except Exception as e:
        return {
            "product_name": product_name,
            "product_id": product_id,
            "product_title": "ERROR",
            "current_price": "ERROR",
            "discount": "ERROR",
            "retailer_id": "ERROR",
            "date": datetime.now().strftime("%Y-%m-%d")
        }

    soup = BeautifulSoup(response.text, "html.parser")

    # æå–å­—æ®µ
    price_meta = soup.find("meta", {"property": "product:price:amount"})
    current_price = price_meta["content"] if price_meta and price_meta.has_attr("content") else ""

    discount_div = soup.find("div", {"data-test-id": "campaign-product-sticker"})
    discount_text = discount_div.get_text(strip=True) if discount_div else ""

    title_meta = soup.find("meta", {"property": "og:title"})
    product_title = title_meta["content"] if title_meta and title_meta.has_attr("content") else ""

    retailer_id_meta = soup.find("meta", {"property": "product:retailer_item_id"})
    retailer_id = retailer_id_meta["content"] if retailer_id_meta and retailer_id_meta.has_attr("content") else ""

    return {
        "product_name": product_name,
        "product_id": product_id,
        "product_title": product_title,
        "current_price": current_price,
        "discount": discount_text,
        "retailer_id": retailer_id,
        "date": datetime.now().strftime("%Y-%m-%d")
    }

# --- é¡µé¢ UI ---
st.set_page_config(page_title="Kjell Product Info Scraper", layout="centered")
st.title("ğŸ” Kjell Product Info Scraper")

st.markdown("""
è¯·ä¸Šä¼ åŒ…å«äº§å“IDå’Œäº§å“åç§°çš„CSVæ–‡ä»¶ã€‚  
CSVæ–‡ä»¶åº”åŒ…å«åˆ—ï¼š**product id** å’Œï¼ˆå¯é€‰ï¼‰**product name**ã€‚
""")

# --- ä¸‹è½½æ¨¡æ¿æŒ‰é’® ---
sample_csv = pd.DataFrame({
    "product id": ["61632", "65412"],
    "product name": ["WD My Cloud Home 4TB", "TP-Link Tapo C520WS"]
})
csv_template = sample_csv.to_csv(index=False)
st.download_button(
    label="ğŸ“¥ ä¸‹è½½CSVæ¨¡æ¿æ–‡ä»¶",
    data=csv_template,
    file_name="kjell_template.csv",
    mime="text/csv"
)

# --- ä¸Šä¼ CSVæ–‡ä»¶ ---
uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    if "product id" not in df.columns:
        st.error("CSV æ–‡ä»¶å¿…é¡»åŒ…å«åä¸º 'product id' çš„åˆ—ã€‚")
    else:
        st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡äº§å“æ•°æ®")
        st.dataframe(df.head())

        if st.button("ğŸš€ å¼€å§‹æŠ“å–"):
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()

            for idx, row in df.iterrows():
                product_id = str(row["product id"]).strip()
                product_name = str(row["product name"]).strip() if "product name" in row else ""
                status_text.text(f"æ­£åœ¨æŠ“å–äº§å“ID: {product_id} ({idx+1}/{len(df)})")
                info = extract_product_info(product_id, product_name)
                results.append(info)
                progress_bar.progress((idx + 1) / len(df))

            status_text.text("âœ… æŠ“å–å®Œæˆï¼")
            results_df = pd.DataFrame(results)[[
                "product_name", "product_id", "product_title", "current_price", "discount", "retailer_id", "date"
            ]]

            csv_buffer = io.StringIO()
            results_df.to_csv(csv_buffer, index=False)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æŠ“å–ç»“æœ (CSVæ ¼å¼)",
                data=csv_buffer.getvalue(),
                file_name=f"kjell_scraped_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
